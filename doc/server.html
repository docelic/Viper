<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<title>Viper - Fully Automated Debian GNU Installation, Configuration and Monitoring</title>
	<link rel="stylesheet" href="style.css" type="text/css" charset="utf-8">
</head>
<body>
<div id="wrapper">
	<div id="body">
		<div id="body-top">
			<div id="body-top-2"></div>
			<div id="body-bot">
				<div id="welcome">
					<h1>&clubs;</h1>
					<h2>VIPER</h2>
<ul>
  <li><a href="index.html">Index page</a></li>
</ul>
					<h2>Quick Start</h2>
<ul>
  <li><a href="server.html">Setting up Viper server</a><br>
  <li><a href="openvz.html">Viper in OpenVZ container</a><br>
  </li>
</ul>
<h2>Guides</h2>
<ul>
  <li><a href="ldap.html">Viper backend overview</a></li>
  <li><a href="configuration.html">Configuration file reference</a><br>
  <li><a href="viper.html">Value syntax reference</a><br><br>
  <li><a href="client.html">Adding clients and hosts</a><br>
  <li><a href="values.html">Adding configuration values</a><br><br>
  <li><a href="components.html">Host installation overview</a></li>
  <li><a href="data.html">Viper LDAP data structure</a></li>
</ul>
<h2>Misc info</h2>
<ul>
  <li><a href="hints.html">Hints &amp; tips</a><br>
  <li><a href="users.html">Viper installations</a><br>
</ul>
<h2>Resources</h2>
<ul>
  <li><a href="http://github.com/docelic/Viper/">Viper @ GitHub</a> </li>
  <li>IRC.OFTC.NET, #viper</li>
  <li><a href="https://lists.hcoop.net/listinfo/viper-users">Mailing list</a></li>
  <li><a href="support.html">Commercial support</a></li>
</ul>
				</div>
				<div id="content">
<h1>Viper - Setting up an installation server</h1>
<p>
Here's the guide to setting up a completely functional Viper
server, on a system running Debian GNU or Ubuntu.
</p>
<p>
The procedure can be followed both standalone on a physical machine, or
inside the OpenVZ container (for openvz, see
<a href="openvz.html">Viper in OpenVZ container</a> first).
</p>
<h2>Download</h2>
<p>
The easiest way to download the files is to clone them from the Git
repository and place in <i>/etc/ldap/viper/</i>.
<pre>
apt-get install git-core

mkdir -p /etc/ldap
cd /etc/ldap
git clone git://github.com/docelic/Viper.git viper
cd viper
</pre>
</p>
<h2>Net::LDAP::FilterMatch fix</h2>
<p>
IMPORTANT
</p>
<p>
Net::LDAP's FilterMatch module contains a bug that you have to patch manually
until it is fixed in the official distribution (track bug progress
report
<a href="http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=540938">here</a>).
</p>
<p>
The patch is simple, and included in Viper distribution as file
<i>support/FilterMatch.pm.patch</i>. Apply it with:
</p>
<pre>
patch -p0 &lt; support/FilterMatch.pm.patch
</pre>
</p>
<h2>Installation</h2>
<p>
To set everything up, you will use script
<a href="../scripts/viper-setup.sh">scripts/viper-setup.sh</a>, either by
directly running it or opening it, reading and choosing which steps
you want to execute.
</p>
<p>
In any case, the purpose of the script is to get Viper up and
running quickly, with a complete default config.
</p>
<p>
The default config is quite independent and can be ran on probably every
machine that does not already run LDAP/DHCP/Puppet server. (If you do run
some of those servers on the host and have important data that cannot be
deleted or forgotten, maybe you have not chosen a good machine for
installing Viper the first time).
</p>
<p>
One of the script's tasks is installing all config files from the
<i>etc/</i> subdirectory onto the real <i>/etc/</i> on the filesystem.
This is done by creating the <i>/etc/...</i> directories and
symlinking the needed config files to Viper's <i>etc/</i> subdirectory.
I find that approach more useful for the moment. If you do not want
symlinks and want to really copy the files, edit the top of
<i>scripts/viper-setup.sh</i> and set CP_ARG="".
</p>
<p>
To install, you can run the setup script as follows:
<pre>
sh scripts/viper-setup.sh
</pre>
<p>
It's worth noting that the script can be ran multiple times without
adverse effects. So if any part of the process fails, you can fix the
problem and run the script again.
</p>
<p>
After the setup script runs and the system gets set up,
you will have a clean, known-good base on which you can run the
test suite, and upon which you can start creating your own configuration.
</p>
<h2>Testing</h2>
<p>
After installation, you should have a working setup populated with default
data. This includes a client with name "c1.com", and three hosts, h1,
h2 and h3.<br>
<br>
Based on that default data, there are tests you can run:
<h3>Testing with ldapsearch</h3>
<pre>
ldapsearch -x -b ou=dhcp
ldapsearch -x -b ou=defaults
ldapsearch -x -b ou=clients

ldapsearch -x -b cn=h2,ou=hosts,o=c1.com,ou=clients

ldapsearch -x -b cn=popularity-contest/participate,ou=hosts,ou=defaults
ldapsearch -x -b cn=debian-installer/locale,cn=h2,ou=hosts,o=c1.com,ou=clients
ldapsearch -x -b cn=ntp/servers,cn=h2,ou=hosts,o=c1.com,ou=clients
</pre>
<h4>ldapsearch test results</h4>
<p>
Ldapsearch query for <i>cn=h2,ou=hosts,o=c1.com,ou=clients</i> is a pretty good
way of determining if everything is working alright. Here's how the output
from the command should look like (the exact attributes are not important,
it's just important that there are no unprocessed values in the output. That
is, nothing with '$' and nothing with only half-populated information).
<pre>
$ ldapsearch -x -b cn=h2,ou=hosts,o=c1.com,ou=clients

# extended LDIF
#
# LDAPv3
# base <cn=h2,ou=hosts,o=c1.com,ou=clients> with scope subtree
# filter: (objectclass=*)
# requesting: ALL
#

# h2, hosts, c1.com, clients
dn: cn=h2,ou=hosts,o=c1.com,ou=clients
objectClass: top
objectClass: device
objectClass: dhcpHost
objectClass: ipHost
objectClass: ieee802Device
objectClass: puppetClient
cn: h2
ipHostNumber: 10.0.1.8
macAddress: 00:11:6b:34:ae:8d
puppetclass: test
puppetclass: ntp::server
dhcpHWAddress: ethernet 00:11:6b:34:ae:8d
dhcpOption: host-name "h2"
dhcpOption: routers 10.0.1.1
dhcpOption: domain-name-servers 192.168.1.254
dhcpOption: nis-domain "c1.com"
dhcpOption: domain-name "c1.com"
dhcpOption: subnet-mask 255.255.255.0
dhcpOption: broadcast-address 10.0.1.255
dhcpStatements: fixed-address 10.0.1.8
hostName: h2
ipNetmaskNumber: 255.255.255.0
clientName: c1.com
ipNetworkNumber: 10.0.1.0
ipBroadcastNumber: 10.0.1.255
domainName: c1.com

# search result
search: 2
result: 0 Success

# numResponses: 2
# numEntries: 1</pre>
</p>
<h3>Testing with scripts/node_data</h3>
<p>
perl scripts/node_data h2.c1.com<br>
</p>
<h3>Testing with scripts/preseed</h3>
<p>
QUERY_STRING=ip=10.0.1.8 perl scripts/preseed<br>
</p>
</p>
<h3>Testing with HTTP client</h3>
<p>
wget http://10.0.1.1/cgi-bin/preseed.cfg?ip=10.0.1.8 -O /tmp/preseed.cfg<br>
</p>
<h2>Post-setup</h2>
<p>
After Viper has been installed and tested, there are a couple final things
that need to be done, that will allow real clients to connect and perform
installation and configuration. Here's the list:
</p>
<h3>HTTP setup</h3>
<p>
Client hosts which are candidates for installation need to be able to
retrieve the preseed file over HTTP, so
the preseed CGI script needs to be linked in the cgi-bin directory.
<p>
</p>
If your cgi-bin dir is in the standard location,
<i>/usr/lib/cgi-bin/</i>, this was already done by the setup script.
</p>
<p>
The client hosts will then reach the preseed file at location
url=http://SERVER/cgi-bin/preseed.cfg.
</p>
<p>
You do not need to specify this location explicitly, because DHCP has been
configured to send "filename" argument to the client host, informing it of the
preseed file URL.
</p>
<p>
This allows you to connect client host to the network, take standard Debian
boot media, choose <i>Advanced -&gt; Automatic installation</i> and complete
the installation without any input, be it at the d-i boot prompt or during
installation.
</p>
<p>
Note that if for some reason you decide not to use Viper's DHCP and/or do not
specify the "filename" option, the d-i installer will try to load the preseed
file from the default location. That location is
http://SERVER/d-i/DISTNAME/preseed.cfg, and you will have to configure
the web server accordingly.
</p>
<h2>EthX interface config</h2>
<p>
By default, Viper expects that each configured client site is on
some subnet, and that the Viper server is accessible at address .1
in that subnet (for example, client "c1.com" that gets installed as part
of test data is on subnet 10.0.1.0/24 and expects Viper server at 10.0.1.1).
</p>
<p>
Changing this isn't impossible (or even hard), but is out of scope of this
document.
</p>
<p>
So, while you were able to run the tests without caring about this, you will
however have to make Viper available on 10.0.1.1 to allow real clients to
connect.
</p>
<p>
Here's how to do it for 10.0.1.1 (the procedure should be repeated for all
other configured subnets). The example scenario here shows Viper host with two
network interfaces: eth0 that uses DHCP and hooks to whatever the host's parent
network and gateway to the Internet is, and eth1 that is intended for Viper and
client subnets.
</p>
<pre>
ifconfig eth1 inet 10.0.1.1 netmask 255.255.255.0
invoke-rc.d ipmasq restart # (If you have it installed)
</pre>
<p>
To configure eth1 on every boot, add it to <i>/etc/network/interfaces</i>
with a stanza like this:
</p>
<pre>
allow-hotplug eth1
iface eth1 inet static
	address 10.0.1.1
	netmask 255.255.255.0
</pre>
<p>
Note: to support further client subnets on the same eth1 interface, you would
use eth1 aliases, such as eth1:1, eth1:2, etc. (Or, in case you installed
Viper in the OpenVZ container, you would create additional ethX devices in
the container and add them all to the bridge vzbr1).
</p>
<h2>Gatewaying</h2>
<p>
Client hosts will most probably need some access to the Internet, even if
you create a local mirror of the Debian packages.
</p>
<p>
In the default configuration, clients are configured to access the net through
Viper server via NAT/IP forwarding.
</p>
<p>
To make that work, you will need to <b>apt-get install ipmasq</b> on the Viper
server. (In case of Viper running in an OpenVZ container, install ipmasq
on the physical host, not the container.)
</p>
<p>
Ipmasq will install and start automatically, properly configuring everything,
but you will have to do a small change in the iptables rules as follows:
</p>
<pre>
# Print out how many forward rules there are. (Then you should
# subtract 2 from that number to get last rule ID. (i.e. 8 - 2 = 6)).

iptables -L FORWARD -v | wc -lr

# Delete last, DROP rule from forward chain and
# change policy to accept

iptables -D FORWARD 6
iptables -P FORWARD ACCEPT
</pre>
</p>
<p>
Also, when you're running Viper as a container under OpenVZ, then the
container itself
will have the .1 addresses (i.e. 10.0.1.1), but you will not be able to use it
as router, because the container can't do forwarding (the 'nat' table only
exists on the physical host).
The physical host in that case will be configured to have eth1
at address 10.0.1.254, so you will need to edit <i>ldifs/c1.com.ldif</i>,
search for "router: " and change the value from 10.0.1.1 to 10.0.1.254 (and
likewise for other subnets), instructing client hosts to use Viper's physical
host for forwarding.
Don't forget to run 'make' in the <i>ldifs/</i> subdirectory to apply the
change.
</p>
<h2>Changing the configuration / adding new clients</h2>
<p>
After Viper installation, testing and preparing for clients to connect,
you can move onto adding new clients and hosts.
</p>
<p>
See <a href="client.html">Adding clients and hosts</a>.
</p>
				  <div class="clear-flat"></div>
				</div>
				<div class="clear"></div>
			</div>
		</div>
	</div>
	<div id="footer">
	<p style="text-align: right;">
	<a href="http://www.thewml.org/">
<img src="images/wml.png" alt="" width="71" height="30"></a>&nbsp;&nbsp;&nbsp;
	<a href="http://www.hcoop.net/">
<img src="images/hcbadge3.gif" alt="" width="88" height="31"></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	</p>
	</div>
</div>
</body>
</html>
