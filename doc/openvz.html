<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<title>Viper - Fully Automated Debian GNU Installation, Configuration and Monitoring</title>
	<link rel="stylesheet" href="style.css" type="text/css" charset="utf-8">
</head>
<body>
<div id="wrapper">
	<div id="body">
		<div id="body-top">
			<div id="body-top-2"></div>
			<div id="body-bot">
				<div id="welcome">
					<h1>&clubs;</h1>
					<h2>VIPER</h2>
<ul>
  <li><a href="index.html">Index page</a></li>
</ul>
					<h2>Quick Start</h2>
<ul>
  <li><a href="server.html">Setting up a Viper server</a><br>
  <li><a href="openvz.html">Viper in OpenVZ container</a><br>
  </li>
</ul>
<h2>Guides</h2>
<ul>
  <li><a href="client.html">Adding clients and hosts</a><br>
  <li><a href="values.html">Adding configuration values</a><br><br>
  <li><a href="configuration.html">Configuration file reference</a><br>
  <li><a href="viper.html">Viper syntax reference</a><br>
</ul>
<h2>Overviews<br>
</h2>
<ul>
  <li><a href="components.html">Host installation procedure </a></li>
  <li><a href="ldap.html">Viper OpenLDAP backend</a></li>
  <li><a href="data.html">Viper LDAP data structure</a></li>
</ul>
<h2>Misc info</h2>
<ul>
  <li><a href="hints.html">Hints &amp; tips</a><br>
  <li><a href="users.html">Viper installations</a><br>
</ul>
<h2>Resources</h2>
<ul>
  <li><a href="http://github.com/docelic/Viper/">Viper @ GitHub</a> </li>
  <li>IRC.OFTC.NET, #viper</li>
  <li><a href="https://lists.hcoop.net/listinfo/viper-users">Mailing list</a></li>
  <li><a href="support.html">Commercial support</a></li>
</ul>
				</div>
				<div id="content">
<h1>Viper in OpenVZ CT</h1>
<p>
This is a practical guide on setting up OpenVZ and creating a container
(CT). In it, you can then install Viper as usual and documented in
<a href="server.html">Setting up a Viper server</a>.
</p>
<p>
Installing Viper under CT can be very useful. For example, I have
Lenovo's S10e ideapad that I carry around, and its host node
is set up as regular desktop machine.
</p>
<p>
However, I want to be able to use it as the Viper install server as
well, without introducing Viper-specific configs to the desktop
system.
</p>
<p>
So OpenVZ container is a solution.
</p>
<h2>Host setup</h2>
<p>
Let's first install vz-enabled kernel, after which you should reboot into
it (make sure you select openvz in the bootloader menu, sometimes it
does not become the default kernel).
</p>
<pre>
apt-get install linux-image-openvz-686
</pre>
<p>
After vz support is installed, we can continue. First, define and load the
necessary sysctl parameters:
</p>
<pre>
sudo sh -c 'echo "net.ipv4.ip_forward=1" &gt;&gt; /etc/sysctl.conf'
sudo sh -c 'echo "net.ipv4.conf.eth0.proxy_arp=1" &gt;&gt; /etc/sysctl.conf'

sudo sysctl -p
</pre>
<h2>vzctl</h2>
<p>
We need to use vzctl version &gt;= 3.0.23. It is currently in Debian testing
or unstable. If dpkg -l vzctl shows a lower version, adjust your sources.list
to also contain testing, do 'apt-get install vzctl' to upgrade vzctl, and then
remove testing from sources.list.
</p>
<pre>
1) Add testing to sources.list
2) apt-get update
3) apt-get install vzctl
4) Remove testing from sources.list
5) apt-get update
</pre>
<h2>Installing the container</h2>
<p>
Now let's debootstrap the Debian installation for container 110, apply
necessary vz configuration and add a SSH key so later we can ssh in
without a password:
</p>
<pre>
debootstrap --arch i386 lenny /var/lib/vz/private/110 \
  http://ftp.us.debian.org/debian

cd /etc/vz/conf

wget 'http://git.openvz.org/?p=vzctl;a=blob_plain;f=etc/conf/ve-unlimited.conf-sample' \
  -O ve-unlimited.conf-sample

vzctl set 110 --applyconfig unlimited --save
vzctl set 110 --diskspace unlimited:unlimited --save
vzctl set 110 --diskinodes unlimited:unlimited --save
echo "OSTEMPLATE=debian-4.0" &gt;&gt; /etc/vz/conf/110.conf

ln -sf /var/lib/vz/private/110 /viper

sed -i -e '/getty/d' /viper/etc/inittab
echo viper &gt; /viper/etc/hostname
echo 127.0.0.1 localhost.localdomain localhost &gt;&gt; /viper/etc/hosts
echo 10.0.1.1 viper &gt;&gt; /viper/etc/hosts

test -r ~/.ssh/id_dsa.pub || ssh-keygen -t dsa
mkdir -p /viper/root/.ssh
cp ~/.ssh/id_dsa.pub /viper/root/.ssh/authorized_keys
</pre>
<p>
Now, to be able to run the DHCP server and have a real ethX interface
within the VZ, we need to use 'veth' instead of the default 'venet'
interface in openvz.
</p>
<p>
Veth devices are added using vzctl --netif_add, and the following
will create devices eth0 and eth1 within the CT. (On the host node,
you'll see veth110.0 and veth110.1).
</p>
<pre>
apt-get install bridge-utils

vzctl set 110 --netif_add eth0,,,,vzbr0 --save
vzctl set 110 --netif_add eth1,,,,vzbr1 --save
</pre>
<p>
(If you get "Invalid syntax" error on the above, as we said, you need
to upgrade your vzctl to at least 3.0.23).
</p>
<h2>Bridging setup on the host</h2>
<p>
The ethX interfaces we have added to the CT are standalone devices that
are not linked to host's ethX. To make this link, we'll use bridging.
</p>
<p>
Simply, bridge is a device to which you just add the devices you
want to bridge.
In our setup, the host's eth0 and eth1 interfaces will become part
of bridges vzbr0 and vzbr1. The container's devices (visible as veth110.0
and veth110.1) are present only while the CT is running, so the vznet.conf
script will take care of adding/removing them from the bridges as CT is
started or stopped.
</p>
<p>
As the host's eth0 and eth1 interfaces become part
of bridges vzbr0 and vzbr1, it means you will remove any eth0 and eth1
configuration in /etc/network/interfaces, add the following bridge
configuration, and remember that from now on, the bridges take over
eth0/eth1, so whatever network operation you want to do on the host, do it on
vzbr0/vzbr1 instead of ethX devices, and you'll get the expected
results.
</p>
<p>
Bridge specifications in /etc/network/interfaces (the listing here
assumes you have two interfaces, eth0 and eth1, where eth0 was a
standard DHCP-configured interface, and eth1 was the device you wanted
to use for Viper and DHCP, so they get to be replaced with bridged
equivalents):
</p>
<pre>
auto vzbr0
iface vzbr0 inet dhcp
	pre-up ifconfig eth0 up
	pre-up brctl addbr vzbr0
	pre-up brctl addif vzbr0 eth0
	post-down ifconfig eth0 down
	post-down brctl delif vzbr0 eth0
	post-down brctl delbr vzbr0

auto vzbr1
iface vzbr1 inet static
	address 10.0.1.254
	netmask 255.255.255.0
	pre-up ifconfig eth1 up
	pre-up brctl addbr vzbr1
	pre-up brctl addif vzbr1 eth1
	post-down ifconfig eth1 down
	post-down brctl delif vzbr1 eth1
	post-down brctl delbr vzbr1
</pre>
<p>
Apply the new host interfaces configuration like this
(execute this ONLY locally, DO NOT run over SSH
as it'll kill your connection and leave machine in the unconfigured state):
</p>
<pre>
ifconfig eth0 0
ifconfig eth1 0

ifup vzbr0
ifup vzbr1
</pre>
<p>
(Note that bridges autodetect network topology change, and that takes a
couple of seconds. When configuring vzbr0, its DHCP client will already
start sending packets before the bridge had autoadjusted itself. This
is alright and has no unwanted effects, except that the DHCP will
take a bit longer to get the address.)
</p>
<p>
Now configure OpenVZ to run the script that automatically changes the veth
devices in the bridges as containers are started or stopped.
</p>
<pre>
test -r /etc/vz/vznet.conf || echo '#!/bin/bash' &gt; /etc/vz/vznet.conf
echo 'EXTERNAL_SCRIPT="/usr/sbin/vznetaddbr"' &gt;&gt; /etc/vz/vznet.conf
chmod 755 /etc/vz/vznet.conf
</pre>
<p>
Start the CT110:
</p>
<pre>
vzctl start 110
</pre>
<h2>Starting the container, configuring the installation</h2>
<pre>
vzctl start 110
vzctl enter 110
</pre>
<p>
/etc/network/interfaces for the container:
</p>
<pre>
auto lo
iface lo inet loopback

auto eth0
iface eth0 inet dhcp

auto eth1
iface eth1 inet static
	address 10.0.1.1
	netmask 255.255.255.0
</pre>
<p>
Bring up interfaces and finish the configuration:
</p>
<pre>
ifup lo
ifup eth0
ifup eth1
</pre>
<p>
Update packages list and install the minimum of tools:
</p>
<pre>
apt-get update

apt-get install openssh-{client,server} vim less
</pre>
<h2>Installing Viper</h2>
<p>
We can now exit the container shell (Ctrl+d) that we have entered via
"vzctl enter 110", and try using SSH to login as usual. The
connection should succeed because we've installed the SSH server in
the container, and it should let us in without a password because we
added the public key to authorized_keys.
</p>
<p>
Just make sure you SSH as the same user whose key you copied (root
or your regular user account).
</p>
<pre>
echo 10.0.1.1 viper>> /etc/hosts

ssh viper
</pre>
<p>
After you've successfully SSH-ed in, you can follow the usual Viper
installation instructions (<a href="server.html">server.html</a>)
as if it was a physical host and not a container.
</p>
				  <div class="clear-flat"></div>
				</div>
				<div class="clear"></div>
			</div>
		</div>
	</div>
	<div id="footer">
	<p style="text-align: right;">
	<a href="http://www.thewml.org/">
<img src="images/wml.png" alt="" width="71" height="30"></a>&nbsp;&nbsp;&nbsp;
	<a href="http://www.hcoop.net/">
<img src="images/hcbadge3.gif" alt="" width="88" height="31"></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	</p>
	</div>
</div>
</body>
</html>
